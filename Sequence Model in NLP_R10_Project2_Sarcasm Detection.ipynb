{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NLP_Project_Sarcasm_Detection_Questions.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pp68FAQf9aMN"},"source":["# Sarcasm Detection\n"," **Acknowledgement**\n","\n","Misra, Rishabh, and Prahal Arora. \"Sarcasm Detection using Hybrid Neural Network.\" arXiv preprint arXiv:1908.07414 (2019).\n","\n","**Required Files given in below link.**\n","\n","https://drive.google.com/drive/folders/1xUnF35naPGU63xwRDVGc-DkZ3M8V5mMk"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"S3Wj_mIZ8S3K"},"source":["## Install `Tensorflow2.0` "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jW2Uk8otQvi8","colab":{}},"source":["!!pip uninstall tensorflow\n","!pip install tensorflow==2.0.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v9kv9tyJ77eF"},"source":["## Get Required Files from Drive"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"D0O_n6OIEVyL","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"ok","timestamp":1592723183563,"user_tz":-330,"elapsed":89033,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"4265859f-7066-4d1d-9383-7226090b39db"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0mgRpOvFMjKR","colab":{},"executionInfo":{"status":"ok","timestamp":1592723193227,"user_tz":-330,"elapsed":1915,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["#Set your project path \n","project_path = '/content/drive/My Drive/Colab Notebooks/NLP/Data/'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"HOqGTRaOCn1O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592723205634,"user_tz":-330,"elapsed":2835,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"88c0a92e-2eda-4d15-a83d-1cf00d65d164"},"source":["cd /content/drive/My Drive/Colab Notebooks/NLP"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/NLP\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rltFe_oFuYxO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592723210483,"user_tz":-330,"elapsed":2819,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["#Loading The libraries\n","import pandas as pd\n","import numpy as np"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WXYwajPeQbRq"},"source":["#**## Reading and Exploring Data**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vAk6BRUh8CqL"},"source":["## Read Data \"Sarcasm_Headlines_Dataset.json\". Explore the data and get  some insights about the data. ( 4 marks)\n","Hint - As its in json format you need to use pandas.read_json function. Give paraemeter lines = True."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"StSLB-T8PuGr","colab":{},"executionInfo":{"status":"ok","timestamp":1592723214852,"user_tz":-330,"elapsed":2599,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["def parseJson(fname):\n","    for line in open(fname, 'r'):\n","        yield eval(line)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"THj-m7eRsyd4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592723221374,"user_tz":-330,"elapsed":6186,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["data = list(parseJson('Data/Sarcasm_Headlines_Dataset.json'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"kVHgYwLnuRj_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592723223681,"user_tz":-330,"elapsed":2272,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["df_data=pd.DataFrame(data)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cyzm3O2luoDx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1592723225083,"user_tz":-330,"elapsed":1536,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"a4ad4744-cb0a-4b6f-c454-665d58b99f29"},"source":["df_data.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>article_link</th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>https://politics.theonion.com/boehner-just-wan...</td>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        article_link  ... is_sarcastic\n","0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n","1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n","2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n","3  https://politics.theonion.com/boehner-just-wan...  ...            1\n","4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n","\n","[5 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z6pXf7A78E2H"},"source":["## Drop `article_link` from dataset. ( 2 marks)\n","As we only need headline text data and is_sarcastic column for this project. We can drop artical link column here."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VLSVsvrlP9qD","colab":{},"executionInfo":{"status":"ok","timestamp":1592723227482,"user_tz":-330,"elapsed":1432,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["df_data=df_data.drop('article_link',axis=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXwfykIou2tR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1592723230918,"user_tz":-330,"elapsed":2214,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"fac4a1fa-b598-4bb5-c1ba-6a57825a7a17"},"source":["df_data.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            headline  is_sarcastic\n","0  former versace store clerk sues over secret 'b...             0\n","1  the 'roseanne' revival catches up to our thorn...             0\n","2  mom starting to fear son's web series closest ...             1\n","3  boehner just wants wife to listen, not come up...             1\n","4  j.k. rowling wishes snape happy birthday in th...             0"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"BupHJJH1y3l6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592718114145,"user_tz":-330,"elapsed":2621,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"b94a8781-4281-44cf-faa8-1ba6a62a881a"},"source":["df_data.shape"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(26709, 2)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"D0h6IOxU8OdH"},"source":["## Get the Length of each line and find the maximum length. ( 4 marks)\n","As different lines are of different length. We need to pad the our sequences using the max length."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BRAsChZAQmr3","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1592723247243,"user_tz":-330,"elapsed":5569,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"19f1144e-9c73-4633-ad92-afa38f808461"},"source":["for i in df_data['headline']:\n","  df_data['len']=len(i)\n","df_data.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>headline</th>\n","      <th>is_sarcastic</th>\n","      <th>len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>former versace store clerk sues over secret 'b...</td>\n","      <td>0</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>the 'roseanne' revival catches up to our thorn...</td>\n","      <td>0</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>mom starting to fear son's web series closest ...</td>\n","      <td>1</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>boehner just wants wife to listen, not come up...</td>\n","      <td>1</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>j.k. rowling wishes snape happy birthday in th...</td>\n","      <td>0</td>\n","      <td>33</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            headline  is_sarcastic  len\n","0  former versace store clerk sues over secret 'b...             0   33\n","1  the 'roseanne' revival catches up to our thorn...             0   33\n","2  mom starting to fear son's web series closest ...             1   33\n","3  boehner just wants wife to listen, not come up...             1   33\n","4  j.k. rowling wishes snape happy birthday in th...             0   33"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"CEo_Qfn8zJCt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592723247252,"user_tz":-330,"elapsed":1490,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"a2b3b9fb-6519-4bc9-c292-2bd6c7cc79ca"},"source":["df_data['len'].max()"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["33"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VPPd0YuPXi2M"},"source":["#**## Modelling**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"35abKfRx8as3"},"source":["## Import required modules required for modelling."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DVel73hYEV4r","colab":{},"executionInfo":{"status":"ok","timestamp":1592723252697,"user_tz":-330,"elapsed":3045,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["import numpy as np\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n","from tensorflow.keras.models import Model, Sequential"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9ziybaD1RdD9"},"source":["# Set Different Parameters for the model. ( 2 marks)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jPw9gAN_EV6m","colab":{},"executionInfo":{"status":"ok","timestamp":1592723252706,"user_tz":-330,"elapsed":1176,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["max_features = 10000\n","maxlen = 33\n","embedding_size = 200"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9abSe-bM8fn9"},"source":["## Apply Keras Tokenizer of headline column of your data.  ( 4 marks)\n","Hint - First create a tokenizer instance using Tokenizer(num_words=max_features) \n","And then fit this tokenizer instance on your data column df['headline'] using .fit_on_texts()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T9Ad26HfTFMS","colab":{},"executionInfo":{"status":"ok","timestamp":1592723256254,"user_tz":-330,"elapsed":2062,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["#Tokenizer for source language\n","tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(df_data['headline']) #Fit it on Source sentences"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Ffi63KsST3P"},"source":["# Define X and y for your model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wnjxBdqmSS4s","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1592723260788,"user_tz":-330,"elapsed":2443,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"2655f926-5782-4fcd-d06e-3c0c139f49aa"},"source":["X = tokenizer.texts_to_sequences(df_data['headline'])\n","X = pad_sequences(X, maxlen = maxlen)\n","y = np.asarray(df_data['is_sarcastic'])\n","\n","print(\"Number of Samples:\", len(X))\n","print(X[0])\n","print(\"Number of Labels: \", len(y))\n","print(y[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Number of Samples: 26709\n","[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0  307  678 3336 2297   47\n","  381 2575    5 2576 8433]\n","Number of Labels:  26709\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WJLyKg-98rH_"},"source":["## Get the Vocabulary size ( 2 marks)\n","Hint : You can use tokenizer.word_index."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"q-2w0gHEUUIo","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1592723265024,"user_tz":-330,"elapsed":2624,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"704e2852-34c5-4a8b-ccdc-e680afeea8e5"},"source":["#Maximum length of sentence\n","max_encoder_seq_length = max([len(txt) for txt in X])\n","print('Maximum sentence length for Source language: ', max_encoder_seq_length)\n","\n","#Source language Vocablury\n","encoder_vocab_size = len(tokenizer.word_index)\n","print('Source language vocablury size: ', encoder_vocab_size)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Maximum sentence length for Source language:  33\n","Source language vocablury size:  29656\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5hjeMi40XcB1"},"source":["#**## Word Embedding**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bUF1TuQa8ux0"},"source":["## Get Glove Word Embeddings"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vq5AIfRtMeZh","colab":{},"executionInfo":{"status":"ok","timestamp":1592723266349,"user_tz":-330,"elapsed":1741,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["glove_file = project_path + \"glove.6B.zip\""],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DJLX_n2WMecA","colab":{},"executionInfo":{"status":"ok","timestamp":1592723346290,"user_tz":-330,"elapsed":80073,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["#Extract Glove embedding zip file\n","from zipfile import ZipFile\n","with ZipFile(glove_file, 'r') as z:\n","  z.extractall()"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9IuXlu8-U3HG"},"source":["# Get the Word Embeddings using Embedding file as given below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"elZ-T5aFGZmZ","colab":{},"executionInfo":{"status":"ok","timestamp":1592723408714,"user_tz":-330,"elapsed":26207,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["EMBEDDING_FILE = './glove.6B.200d.txt'\n","\n","embeddings = {}\n","for o in open(EMBEDDING_FILE):\n","    word = o.split(\" \")[0]\n","    # print(word)\n","    embd = o.split(\" \")[1:]\n","    embd = np.asarray(embd, dtype='float32')\n","    # print(embd)\n","    embeddings[word] = embd\n","\n"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bTPxveDmVCrA"},"source":["# Create a weight matrix for words in training docs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xQgOhiywU9nU","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1592723450007,"user_tz":-330,"elapsed":1763,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"6416886b-4de6-4e68-85bd-c0dfcee9290b"},"source":["num_words=encoder_vocab_size+1\n","embedding_matrix = np.zeros((num_words, 200))\n","\n","for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[i] = embedding_vector\n","\n","len(embeddings.values())"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["400000"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u7IbWuEX82Ra"},"source":["## Create and Compile your Model  ( 7 marks)\n","Hint - Use Sequential model instance and then add Embedding layer, Bidirectional(LSTM) layer, then dense and dropout layers as required. \n","In the end add a final dense layer with sigmoid activation for binary classification.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d7jhsSgYXG4l","colab":{},"executionInfo":{"status":"ok","timestamp":1592723465971,"user_tz":-330,"elapsed":9224,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["model = Sequential()\n","# Embedding layer \n","model.add(Embedding(num_words, embedding_size, weights = [embedding_matrix]))\n","# Bidirectional LSTM layer \n","model.add(Bidirectional(LSTM(128, return_sequences = True)))\n","#Dense Layer\n","model.add(Dense(1,activation='sigmoid'))"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QSpsfIzKP6u","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592723481351,"user_tz":-330,"elapsed":1669,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}}},"source":["model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IJFMxZwMWoTw"},"source":["# Fit your model with a batch size of 100 and validation_split = 0.2. and state the validation accuracy ( 5 marks)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZpVkajCcWnRK","colab":{"base_uri":"https://localhost:8080/","height":239},"executionInfo":{"status":"ok","timestamp":1592724394937,"user_tz":-330,"elapsed":105837,"user":{"displayName":"Prasanna Siva","photoUrl":"","userId":"00020700508952758165"}},"outputId":"82b98d85-b285-45a8-fe0e-1b01d0165baa"},"source":["batch_size = 100\n","epochs = 5\n","\n","## Add your code here ##\n","model.fit(X,y,\n","          epochs=epochs,\n","          batch_size=batch_size,          \n","          verbose=1,\n","          validation_split=0.2)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","214/214 [==============================] - 21s 97ms/step - loss: 0.0920 - accuracy: 0.9659 - val_loss: 0.3867 - val_accuracy: 0.8672\n","Epoch 2/5\n","214/214 [==============================] - 21s 100ms/step - loss: 0.0730 - accuracy: 0.9741 - val_loss: 0.4471 - val_accuracy: 0.8669\n","Epoch 3/5\n","214/214 [==============================] - 21s 96ms/step - loss: 0.0584 - accuracy: 0.9796 - val_loss: 0.4884 - val_accuracy: 0.8651\n","Epoch 4/5\n","214/214 [==============================] - 20s 95ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.5675 - val_accuracy: 0.8649\n","Epoch 5/5\n","214/214 [==============================] - 21s 96ms/step - loss: 0.0321 - accuracy: 0.9897 - val_loss: 0.6601 - val_accuracy: 0.8598\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f99a5846470>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"eDmFn067yifF","colab_type":"text"},"source":["The validation accuracy is 85.98"]},{"cell_type":"code","metadata":{"id":"432G10d2ysSY","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}